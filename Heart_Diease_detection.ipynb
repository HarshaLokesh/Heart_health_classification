{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart_diease_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4wYeqN0aTvDpzN624Ifrt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshaLokesh/Heart_health_classification/blob/main/Heart_Diease_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "N0RZnGJoomhs",
        "outputId": "853ffd0e-b300-4a90-9a45-ca8c81b80e5a"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6efe23a9-c6fd-4d22-8a30-c2e2d4b90f45\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6efe23a9-c6fd-4d22-8a30-c2e2d4b90f45\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heart_dataset.csv to heart_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EBuZSc4wePEF",
        "outputId": "2a235b3f-1d9c-4620-fd8c-10820d76def5"
      },
      "source": [
        "import pandas as pd\n",
        "heart = pd.read_csv(\"heart_dataset.csv\")\n",
        "data = heart.copy()\n",
        "\n",
        "#shuffle the data set \n",
        "df = data.sample(frac=1).reset_index(drop=True) \n",
        "\n",
        "df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>178</td>\n",
              "      <td>270</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>205</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>155</td>\n",
              "      <td>269</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>213</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>126</td>\n",
              "      <td>282</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>135</td>\n",
              "      <td>304</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>223</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>181</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>267</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0   59    1   3       178   270    0  ...      0      4.2      0   0     3       1\n",
              "1   55    0   0       128   205    0  ...      1      2.0      1   1     3       0\n",
              "2   65    0   2       155   269    0  ...      0      0.8      2   0     2       1\n",
              "3   43    0   2       122   213    0  ...      0      0.2      1   0     2       1\n",
              "4   53    0   0       138   234    0  ...      0      0.0      2   0     2       1\n",
              "5   50    0   0       110   254    0  ...      0      0.0      2   0     2       1\n",
              "6   35    1   0       126   282    0  ...      1      0.0      2   0     3       0\n",
              "7   54    0   2       135   304    1  ...      0      0.0      2   0     2       1\n",
              "8   40    1   0       152   223    0  ...      0      0.0      2   0     3       0\n",
              "9   62    1   0       120   267    0  ...      1      1.8      1   2     3       0\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SoIgHAfRy_yc",
        "outputId": "ba9d6cee-a95b-49bc-8b30-5f03548fae74"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>54.366337</td>\n",
              "      <td>0.683168</td>\n",
              "      <td>0.966997</td>\n",
              "      <td>131.623762</td>\n",
              "      <td>246.264026</td>\n",
              "      <td>0.148515</td>\n",
              "      <td>0.528053</td>\n",
              "      <td>149.646865</td>\n",
              "      <td>0.326733</td>\n",
              "      <td>1.039604</td>\n",
              "      <td>1.399340</td>\n",
              "      <td>0.729373</td>\n",
              "      <td>2.313531</td>\n",
              "      <td>0.544554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.082101</td>\n",
              "      <td>0.466011</td>\n",
              "      <td>1.032052</td>\n",
              "      <td>17.538143</td>\n",
              "      <td>51.830751</td>\n",
              "      <td>0.356198</td>\n",
              "      <td>0.525860</td>\n",
              "      <td>22.905161</td>\n",
              "      <td>0.469794</td>\n",
              "      <td>1.161075</td>\n",
              "      <td>0.616226</td>\n",
              "      <td>1.022606</td>\n",
              "      <td>0.612277</td>\n",
              "      <td>0.498835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>211.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>133.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>274.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>564.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age         sex          cp  ...          ca        thal      target\n",
              "count  303.000000  303.000000  303.000000  ...  303.000000  303.000000  303.000000\n",
              "mean    54.366337    0.683168    0.966997  ...    0.729373    2.313531    0.544554\n",
              "std      9.082101    0.466011    1.032052  ...    1.022606    0.612277    0.498835\n",
              "min     29.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     47.500000    0.000000    0.000000  ...    0.000000    2.000000    0.000000\n",
              "50%     55.000000    1.000000    1.000000  ...    0.000000    2.000000    1.000000\n",
              "75%     61.000000    1.000000    2.000000  ...    1.000000    3.000000    1.000000\n",
              "max     77.000000    1.000000    3.000000  ...    4.000000    3.000000    1.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0_OvM_rwXyl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5tY-7Jlz4Ls",
        "outputId": "09af8b7b-9d5f-4f07-f9ce-91c3cdb7d0bd"
      },
      "source": [
        "X=df.drop('target',axis=1).values    \n",
        "y=df['target'].values\n",
        "X,y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[59.,  1.,  3., ...,  0.,  0.,  3.],\n",
              "        [55.,  0.,  0., ...,  1.,  1.,  3.],\n",
              "        [65.,  0.,  2., ...,  2.,  0.,  2.],\n",
              "        ...,\n",
              "        [59.,  1.,  0., ...,  1.,  0.,  3.],\n",
              "        [59.,  1.,  3., ...,  1.,  0.,  3.],\n",
              "        [56.,  1.,  3., ...,  1.,  0.,  3.]]),\n",
              " array([1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "        0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "        0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "        0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "        1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "        1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "        1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0rzVXv-ACMa",
        "outputId": "d118c71c-40bf-4135-f29d-c0d3e9ab5fed"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (242, 13) (242,)\n",
            "Test set: (61, 13) (61,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grMX3A9ZNQOm"
      },
      "source": [
        "1. Decision tree classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B7llbciAjtO",
        "outputId": "ec71a50b-59ad-46c9-b8ff-24f085c1bb62"
      },
      "source": [
        "Decision_Tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
        "Decision_Tree.fit(X_train,y_train)\n",
        "Tree_ytest = Decision_Tree.predict(X_test)\n",
        "\n",
        "Decision_Tree_Score = metrics.accuracy_score(y_test, Tree_ytest) \n",
        "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, Decision_Tree.predict(X_train)))\n",
        "print(\"DecisionTrees Accuracy: \", Decision_Tree_Score)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set Accuracy:  0.8553719008264463\n",
            "DecisionTrees Accuracy:  0.8524590163934426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm2iZBnrNaTY"
      },
      "source": [
        "2. Random forest classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31BC8cLqLPTX",
        "outputId": "6cf8288e-cfc0-4065-99f7-cbc6a8d65440"
      },
      "source": [
        "RFC = RandomForestClassifier(max_depth=7)\n",
        "RFC.fit(X_train,y_train)\n",
        "Tree_ytest = RFC.predict(X_test)\n",
        "\n",
        "RFC_Score = metrics.accuracy_score(y_test, Tree_ytest) \n",
        "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, RFC.predict(X_train)))\n",
        "print(\"RFC Accuracy: \", RFC_Score)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set Accuracy:  0.987603305785124\n",
            "RFC Accuracy:  0.8360655737704918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb_uN_A0kGt7"
      },
      "source": [
        "3. Support vector machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAV6UAfUNgvs",
        "outputId": "a7f21996-0769-4d4d-9165-86a4e86056b8"
      },
      "source": [
        "from sklearn import svm\n",
        "SVM = svm.SVC(kernel='rbf')\n",
        "SVM.fit(X_train, y_train) \n",
        "SVM_ytest = SVM.predict(X_test)\n",
        "\n",
        "SVM_Score = metrics.accuracy_score(y_test, SVM_ytest)\n",
        "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, SVM.predict(X_train)))\n",
        "print(\"SVM Accuracy: \", SVM_Score)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set Accuracy:  0.6487603305785123\n",
            "SVM Accuracy:  0.6721311475409836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1prCZed8oDHT"
      },
      "source": [
        "4. K nearest neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfPVUj2CkLIj",
        "outputId": "32aacf08-034c-4c5e-d187-e56bf3055ae6"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNN = KNeighborsClassifier(n_neighbors = 7).fit(X_train,y_train)\n",
        "knn_ytest = KNN.predict(X_test)\n",
        "\n",
        "KNN_Score = metrics.accuracy_score(y_test, knn_ytest)                                               \n",
        "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, KNN.predict(X_train)))\n",
        "print(\"KNN Accuracy: \",KNN_Score )\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set Accuracy:  0.756198347107438\n",
            "KNN Accuracy:  0.7049180327868853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VilPMgIDk-bV"
      },
      "source": [
        "5. Neural network method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGI4UvBboQjM",
        "outputId": "493309e5-33e3-4503-b518-95de8f6bfd72"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "heart = pd.read_csv(\"heart_dataset.csv\")\n",
        "data = heart.copy()\n",
        "\n",
        "X=df.drop('target',axis=1).values    \n",
        "y=df['target'].values\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X,y)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "keras.layers.Dense(32, activation='relu',input_shape=X_train.shape[1:]),\n",
        "keras.layers.Dense(16, activation='relu'),\n",
        "keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=125,validation_data=(X_valid, y_valid))\n",
        "\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "6/6 [==============================] - 1s 30ms/step - loss: 0.4919 - accuracy: 0.5118 - val_loss: 0.4221 - val_accuracy: 0.4386\n",
            "Epoch 2/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.5471 - val_loss: 0.3522 - val_accuracy: 0.5263\n",
            "Epoch 3/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2995 - accuracy: 0.5941 - val_loss: 0.3134 - val_accuracy: 0.5614\n",
            "Epoch 4/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.6294 - val_loss: 0.2882 - val_accuracy: 0.5439\n",
            "Epoch 5/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2395 - accuracy: 0.6529 - val_loss: 0.2708 - val_accuracy: 0.5439\n",
            "Epoch 6/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2214 - accuracy: 0.6765 - val_loss: 0.2594 - val_accuracy: 0.5789\n",
            "Epoch 7/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.2075 - accuracy: 0.7118 - val_loss: 0.2475 - val_accuracy: 0.5965\n",
            "Epoch 8/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1942 - accuracy: 0.7294 - val_loss: 0.2399 - val_accuracy: 0.6491\n",
            "Epoch 9/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1861 - accuracy: 0.7471 - val_loss: 0.2338 - val_accuracy: 0.6491\n",
            "Epoch 10/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1791 - accuracy: 0.7765 - val_loss: 0.2279 - val_accuracy: 0.6491\n",
            "Epoch 11/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.7824 - val_loss: 0.2227 - val_accuracy: 0.6667\n",
            "Epoch 12/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1670 - accuracy: 0.7882 - val_loss: 0.2192 - val_accuracy: 0.6667\n",
            "Epoch 13/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1621 - accuracy: 0.7824 - val_loss: 0.2156 - val_accuracy: 0.6842\n",
            "Epoch 14/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1580 - accuracy: 0.7824 - val_loss: 0.2122 - val_accuracy: 0.6842\n",
            "Epoch 15/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1545 - accuracy: 0.7882 - val_loss: 0.2090 - val_accuracy: 0.6842\n",
            "Epoch 16/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1516 - accuracy: 0.7941 - val_loss: 0.2063 - val_accuracy: 0.7018\n",
            "Epoch 17/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1491 - accuracy: 0.7882 - val_loss: 0.2039 - val_accuracy: 0.7018\n",
            "Epoch 18/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1460 - accuracy: 0.8000 - val_loss: 0.2010 - val_accuracy: 0.7193\n",
            "Epoch 19/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1425 - accuracy: 0.8059 - val_loss: 0.1991 - val_accuracy: 0.7193\n",
            "Epoch 20/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1406 - accuracy: 0.8294 - val_loss: 0.1966 - val_accuracy: 0.7193\n",
            "Epoch 21/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1381 - accuracy: 0.8176 - val_loss: 0.1963 - val_accuracy: 0.7193\n",
            "Epoch 22/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1366 - accuracy: 0.8235 - val_loss: 0.1938 - val_accuracy: 0.7193\n",
            "Epoch 23/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1349 - accuracy: 0.8294 - val_loss: 0.1918 - val_accuracy: 0.7193\n",
            "Epoch 24/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.8412 - val_loss: 0.1910 - val_accuracy: 0.7193\n",
            "Epoch 25/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.8353 - val_loss: 0.1900 - val_accuracy: 0.7193\n",
            "Epoch 26/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1293 - accuracy: 0.8353 - val_loss: 0.1888 - val_accuracy: 0.7193\n",
            "Epoch 27/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1274 - accuracy: 0.8412 - val_loss: 0.1880 - val_accuracy: 0.7193\n",
            "Epoch 28/125\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1261 - accuracy: 0.8412 - val_loss: 0.1869 - val_accuracy: 0.7193\n",
            "Epoch 29/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.8353 - val_loss: 0.1858 - val_accuracy: 0.7193\n",
            "Epoch 30/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.8353 - val_loss: 0.1854 - val_accuracy: 0.7193\n",
            "Epoch 31/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1224 - accuracy: 0.8353 - val_loss: 0.1835 - val_accuracy: 0.7368\n",
            "Epoch 32/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1217 - accuracy: 0.8353 - val_loss: 0.1827 - val_accuracy: 0.7368\n",
            "Epoch 33/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.8412 - val_loss: 0.1813 - val_accuracy: 0.7368\n",
            "Epoch 34/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.8471 - val_loss: 0.1803 - val_accuracy: 0.7368\n",
            "Epoch 35/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.8412 - val_loss: 0.1799 - val_accuracy: 0.7544\n",
            "Epoch 36/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.8471 - val_loss: 0.1797 - val_accuracy: 0.7544\n",
            "Epoch 37/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.8471 - val_loss: 0.1796 - val_accuracy: 0.7544\n",
            "Epoch 38/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1157 - accuracy: 0.8471 - val_loss: 0.1787 - val_accuracy: 0.7544\n",
            "Epoch 39/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.8529 - val_loss: 0.1780 - val_accuracy: 0.7544\n",
            "Epoch 40/125\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1139 - accuracy: 0.8471 - val_loss: 0.1774 - val_accuracy: 0.7544\n",
            "Epoch 41/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.8529 - val_loss: 0.1766 - val_accuracy: 0.7544\n",
            "Epoch 42/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1127 - accuracy: 0.8471 - val_loss: 0.1761 - val_accuracy: 0.7719\n",
            "Epoch 43/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1122 - accuracy: 0.8588 - val_loss: 0.1759 - val_accuracy: 0.7544\n",
            "Epoch 44/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.8588 - val_loss: 0.1757 - val_accuracy: 0.7544\n",
            "Epoch 45/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.8529 - val_loss: 0.1759 - val_accuracy: 0.7544\n",
            "Epoch 46/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.8471 - val_loss: 0.1754 - val_accuracy: 0.7544\n",
            "Epoch 47/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1092 - accuracy: 0.8412 - val_loss: 0.1742 - val_accuracy: 0.7544\n",
            "Epoch 48/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.8471 - val_loss: 0.1739 - val_accuracy: 0.7719\n",
            "Epoch 49/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.8529 - val_loss: 0.1725 - val_accuracy: 0.7719\n",
            "Epoch 50/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8706 - val_loss: 0.1718 - val_accuracy: 0.7719\n",
            "Epoch 51/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.8706 - val_loss: 0.1726 - val_accuracy: 0.7719\n",
            "Epoch 52/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.8647 - val_loss: 0.1723 - val_accuracy: 0.7719\n",
            "Epoch 53/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.8647 - val_loss: 0.1723 - val_accuracy: 0.7544\n",
            "Epoch 54/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8529 - val_loss: 0.1720 - val_accuracy: 0.7544\n",
            "Epoch 55/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.8588 - val_loss: 0.1708 - val_accuracy: 0.7719\n",
            "Epoch 56/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8588 - val_loss: 0.1706 - val_accuracy: 0.7719\n",
            "Epoch 57/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.8588 - val_loss: 0.1708 - val_accuracy: 0.7719\n",
            "Epoch 58/125\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1022 - accuracy: 0.8588 - val_loss: 0.1705 - val_accuracy: 0.7895\n",
            "Epoch 59/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.8647 - val_loss: 0.1709 - val_accuracy: 0.7895\n",
            "Epoch 60/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1013 - accuracy: 0.8588 - val_loss: 0.1710 - val_accuracy: 0.7895\n",
            "Epoch 61/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1009 - accuracy: 0.8588 - val_loss: 0.1716 - val_accuracy: 0.7719\n",
            "Epoch 62/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.8647 - val_loss: 0.1710 - val_accuracy: 0.7719\n",
            "Epoch 63/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.8647 - val_loss: 0.1701 - val_accuracy: 0.7895\n",
            "Epoch 64/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0994 - accuracy: 0.8647 - val_loss: 0.1704 - val_accuracy: 0.7719\n",
            "Epoch 65/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.8647 - val_loss: 0.1701 - val_accuracy: 0.7719\n",
            "Epoch 66/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.8647 - val_loss: 0.1698 - val_accuracy: 0.7895\n",
            "Epoch 67/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0982 - accuracy: 0.8647 - val_loss: 0.1699 - val_accuracy: 0.7719\n",
            "Epoch 68/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0980 - accuracy: 0.8706 - val_loss: 0.1693 - val_accuracy: 0.7895\n",
            "Epoch 69/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0974 - accuracy: 0.8706 - val_loss: 0.1679 - val_accuracy: 0.7895\n",
            "Epoch 70/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.8824 - val_loss: 0.1676 - val_accuracy: 0.7895\n",
            "Epoch 71/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.8824 - val_loss: 0.1679 - val_accuracy: 0.7895\n",
            "Epoch 72/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.8765 - val_loss: 0.1675 - val_accuracy: 0.7895\n",
            "Epoch 73/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.8824 - val_loss: 0.1674 - val_accuracy: 0.7895\n",
            "Epoch 74/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.8824 - val_loss: 0.1676 - val_accuracy: 0.7895\n",
            "Epoch 75/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0944 - accuracy: 0.8765 - val_loss: 0.1679 - val_accuracy: 0.7895\n",
            "Epoch 76/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0939 - accuracy: 0.8765 - val_loss: 0.1675 - val_accuracy: 0.7895\n",
            "Epoch 77/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0936 - accuracy: 0.8824 - val_loss: 0.1677 - val_accuracy: 0.7895\n",
            "Epoch 78/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.8765 - val_loss: 0.1668 - val_accuracy: 0.7895\n",
            "Epoch 79/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.8765 - val_loss: 0.1661 - val_accuracy: 0.7895\n",
            "Epoch 80/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0919 - accuracy: 0.8824 - val_loss: 0.1659 - val_accuracy: 0.7895\n",
            "Epoch 81/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0916 - accuracy: 0.8941 - val_loss: 0.1658 - val_accuracy: 0.7895\n",
            "Epoch 82/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0912 - accuracy: 0.8882 - val_loss: 0.1649 - val_accuracy: 0.7895\n",
            "Epoch 83/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.8941 - val_loss: 0.1648 - val_accuracy: 0.7895\n",
            "Epoch 84/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.8941 - val_loss: 0.1654 - val_accuracy: 0.7895\n",
            "Epoch 85/125\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0898 - accuracy: 0.8941 - val_loss: 0.1653 - val_accuracy: 0.7895\n",
            "Epoch 86/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.8882 - val_loss: 0.1647 - val_accuracy: 0.7895\n",
            "Epoch 87/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.8941 - val_loss: 0.1644 - val_accuracy: 0.7895\n",
            "Epoch 88/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.8941 - val_loss: 0.1645 - val_accuracy: 0.7895\n",
            "Epoch 89/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.8941 - val_loss: 0.1644 - val_accuracy: 0.7895\n",
            "Epoch 90/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0877 - accuracy: 0.8941 - val_loss: 0.1643 - val_accuracy: 0.7895\n",
            "Epoch 91/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.8941 - val_loss: 0.1643 - val_accuracy: 0.7895\n",
            "Epoch 92/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.8941 - val_loss: 0.1642 - val_accuracy: 0.7895\n",
            "Epoch 93/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0865 - accuracy: 0.8941 - val_loss: 0.1642 - val_accuracy: 0.7895\n",
            "Epoch 94/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.8941 - val_loss: 0.1641 - val_accuracy: 0.7895\n",
            "Epoch 95/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0856 - accuracy: 0.8941 - val_loss: 0.1640 - val_accuracy: 0.7895\n",
            "Epoch 96/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.8941 - val_loss: 0.1641 - val_accuracy: 0.7895\n",
            "Epoch 97/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.8941 - val_loss: 0.1638 - val_accuracy: 0.7895\n",
            "Epoch 98/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0845 - accuracy: 0.8941 - val_loss: 0.1639 - val_accuracy: 0.7895\n",
            "Epoch 99/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.8941 - val_loss: 0.1640 - val_accuracy: 0.7895\n",
            "Epoch 100/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.8941 - val_loss: 0.1641 - val_accuracy: 0.7895\n",
            "Epoch 101/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.8941 - val_loss: 0.1639 - val_accuracy: 0.7895\n",
            "Epoch 102/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.8941 - val_loss: 0.1646 - val_accuracy: 0.7719\n",
            "Epoch 103/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9000 - val_loss: 0.1643 - val_accuracy: 0.7719\n",
            "Epoch 104/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.8941 - val_loss: 0.1644 - val_accuracy: 0.7719\n",
            "Epoch 105/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9000 - val_loss: 0.1643 - val_accuracy: 0.7719\n",
            "Epoch 106/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.8941 - val_loss: 0.1639 - val_accuracy: 0.7719\n",
            "Epoch 107/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.8941 - val_loss: 0.1636 - val_accuracy: 0.7719\n",
            "Epoch 108/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9000 - val_loss: 0.1631 - val_accuracy: 0.7719\n",
            "Epoch 109/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0808 - accuracy: 0.8941 - val_loss: 0.1628 - val_accuracy: 0.7719\n",
            "Epoch 110/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9000 - val_loss: 0.1631 - val_accuracy: 0.7719\n",
            "Epoch 111/125\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9059 - val_loss: 0.1624 - val_accuracy: 0.7895\n",
            "Epoch 112/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9059 - val_loss: 0.1632 - val_accuracy: 0.7719\n",
            "Epoch 113/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0796 - accuracy: 0.9118 - val_loss: 0.1632 - val_accuracy: 0.7719\n",
            "Epoch 114/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9118 - val_loss: 0.1632 - val_accuracy: 0.7895\n",
            "Epoch 115/125\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0788 - accuracy: 0.9118 - val_loss: 0.1631 - val_accuracy: 0.7895\n",
            "Epoch 116/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9118 - val_loss: 0.1630 - val_accuracy: 0.7895\n",
            "Epoch 117/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9118 - val_loss: 0.1621 - val_accuracy: 0.7895\n",
            "Epoch 118/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9118 - val_loss: 0.1622 - val_accuracy: 0.7895\n",
            "Epoch 119/125\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0778 - accuracy: 0.9059 - val_loss: 0.1622 - val_accuracy: 0.7895\n",
            "Epoch 120/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9118 - val_loss: 0.1626 - val_accuracy: 0.7895\n",
            "Epoch 121/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9118 - val_loss: 0.1625 - val_accuracy: 0.7895\n",
            "Epoch 122/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9118 - val_loss: 0.1622 - val_accuracy: 0.7895\n",
            "Epoch 123/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9118 - val_loss: 0.1626 - val_accuracy: 0.7895\n",
            "Epoch 124/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9176 - val_loss: 0.1622 - val_accuracy: 0.7895\n",
            "Epoch 125/125\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9118 - val_loss: 0.1622 - val_accuracy: 0.7895\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.8026\n",
            "Accuracy: 80.26\n"
          ]
        }
      ]
    }
  ]
}